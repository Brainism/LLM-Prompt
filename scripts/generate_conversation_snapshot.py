from __future__ import annotations
import argparse, json, csv, os, shutil, zipfile
from pathlib import Path

DEFAULT_FILES = [
    "scripts",
    "prompts/main.csv",
    "split_manifest.json",
    "run_full_pipeline.cmd",
    "recent_commands.txt",
    "run_full_pipeline.log",
    "ollama_models.txt",
    "results/raw/general.jsonl",
    "results/raw/instructed.jsonl",
    "results/quantitative/metrics_per_item.json",
    "tables"
]

def safe_add(zf: zipfile.ZipFile, path: Path, arc_root: Path):
    if not path.exists():
        return
    if path.is_dir():
        for p in sorted(path.rglob("*")):
            if p.is_file():
                zf.write(p, p.relative_to(arc_root))
    else:
        zf.write(path, path.relative_to(arc_root))

def sample_jsonl(path: Path, max_lines=50):
    out = []
    if not path.exists():
        return out
    with path.open("r", encoding="utf-8", errors="replace") as fh:
        for i, ln in enumerate(fh):
            if i >= max_lines: break
            ln = ln.strip()
            if not ln: continue
            try:
                out.append(json.loads(ln))
            except Exception:
                out.append({"_raw": ln})
    return out

def build_snapshot_md(root: Path, include_files, sample_count=5):
    lines = []
    lines.append("# Conversation Snapshot\n\n")
    lines.append("## Quick summary\n\n")
    lines.append("- Generated by: scripts/generate_conversation_snapshot.py\n")
    lines.append("- Root: `%s`\n\n" % str(root))
    rc = root / "recent_commands.txt"
    lines.append("## Recent commands (tail 50)\n\n")
    if rc.exists():
        with rc.open("r", encoding="utf-8", errors="replace") as fh:
            allc = fh.read().strip().splitlines()
            tail = allc[-50:]
            lines.append("```\n" + "\n".join(tail) + "\n```\n\n")
    else:
        lines.append("- recent_commands.txt not found\n\n")
    lines.append("## Sampled outputs (up to %d lines each)\n\n" % sample_count)
    for sample_path in ["results/raw/general.jsonl", "results/raw/instructed.jsonl"]:
        p = root / sample_path
        lines.append(f"### {sample_path}\n\n")
        if p.exists():
            items = sample_jsonl(p, max_lines=sample_count)
            for it in items:
                lines.append("```json\n" + json.dumps(it, ensure_ascii=False, indent=2) + "\n```\n")
        else:
            lines.append("- missing\n\n")
    m = root / "results/quantitative/metrics_per_item.json"
    if m.exists():
        try:
            doc = json.loads(m.read_text(encoding="utf-8"))
            per = doc.get("per_item", [])
            lines.append("## Metrics summary (metrics_per_item.json)\n\n")
            lines.append(f"- n_per_item entries: {len(per)}\n\n")
        except Exception:
            lines.append("- Could not parse metrics_per_item.json\n\n")
    # TODO
    lines.append("## Open issues (auto-detected)\n\n")
    err_items = []
    for pth in ["results/raw/general.jsonl","results/raw/instructed.jsonl"]:
        p = root / pth
        if p.exists():
            with p.open("r", encoding="utf-8", errors="replace") as fh:
                for ln in fh:
                    if '"error"' in ln or '[ERR]' in ln or 'TimeoutExpired' in ln:
                        err_items.append(pth)
                        break
    if err_items:
        lines.append("- Error/timeout present in: %s\n\n" % ", ".join(sorted(set(err_items))))
    else:
        lines.append("- No obvious error markers found in raw outputs.\n\n")
    lines.append("## Recommended next steps (from snapshot generator)\n\n")
    lines.append("1. Inspect `results/raw/*` entries containing an `error` key or that are empty outputs.\n")
    lines.append("2. Run `python scripts/inspect_item.py <ID>` for a few failing IDs (e.g. ones in compare_outputs diffs).\n")
    lines.append("3. Re-run only failed items with `--use-cli` toggled or increase timeout.\n\n")
    return "".join(lines)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--root", default=".", help="Repo root (default current dir)")
    ap.add_argument("--out", default="conversation_snapshot.zip", help="Output zip path")
    ap.add_argument("--include", nargs="*", help="Extra files to include")
    ap.add_argument("--sample", type=int, default=5, help="Sample size for jsonl preview")
    args = ap.parse_args()

    root = Path(args.root).resolve()
    outp = Path(args.out).resolve()

    include = list(DEFAULT_FILES)
    if args.include:
        include.extend(args.include)

    tmpdir = root / ".chat_snapshot_tmp"
    if tmpdir.exists():
        shutil.rmtree(tmpdir)
    tmpdir.mkdir()

    md = build_snapshot_md(root, include, sample_count=args.sample)
    (tmpdir / "conversation_snapshot.md").write_text(md, encoding="utf-8")

    with zipfile.ZipFile(outp, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.write(tmpdir / "conversation_snapshot.md", "conversation_snapshot.md")
        for p in include:
            pth = root / p
            if pth.exists():
                if pth.is_dir():
                    for f in sorted(pth.rglob("*")):
                        if f.is_file():
                            if ".venv" in str(f): continue
                            zf.write(f, f.relative_to(root))
                else:
                    zf.write(pth, pth.relative_to(root))

    shutil.rmtree(tmpdir)
    print("Wrote snapshot zip:", outp)

if __name__ == "__main__":
    main()